version: "3.7"

services:
  namenode:
    image: gudari/hadoop:2.7.7
    container_name: namenode
    hostname: namenode
    ports:
    - "50070:50070"
    volumes:
      - ./data/namenode:/hadoop/dfs/name
    environment:
      - CLUSTER_NAME=local
    env_file:
      - ./hadoop.env

  datanode:
    image: gudari/hadoop:2.7.7
    container_name: datanode
    hostname: datanode
    volumes:
      - ./data/datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:50070"
    depends_on:
      - namenode
    env_file:
      - ./hadoop.env

  spark-master:
    image: gudari/spark:2.4.5
    container_name: spark-master
    hostname: spark-master
    ports:
    - "8080:8080"
    - "4040:4040"
    environment:
        SERVICE_PRECONDITION: "namenode:50070"
    depends_on:
    - namenode
    - datanode
    env_file:
    - ./spark.env
    - ./hadoop.env

  spark-worker:
    image: gudari/spark:2.4.5
    container_name: spark-worker
    hostname: spark-worker
    ports:
    - "8081:8081"
    environment:
        SERVICE_PRECONDITION: "namenode:50070"
    depends_on:
    - namenode
    - datanode
    env_file:
    - ./spark.env
    - ./hadoop.env




  hoster:
    image: dvdarias/docker-hoster
    container_name: hadoop_hoster
    hostname: hadoop_hoster
    volumes:
      - /var/run/docker.sock:/tmp/docker.sock
      - /etc/hosts:/tmp/hosts
